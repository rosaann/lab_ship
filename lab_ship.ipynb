{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "from skimage.util import montage\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "gc.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLING_MODE = 'Simple'\n",
    "\n",
    "NET_SCALING = None\n",
    "\n",
    "IMG_SCALING = (1, 1)\n",
    "\n",
    "VALIDATION_SET_SIZE = 400\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "input_dir = '../'\n",
    "\n",
    "train_image_dir = os.path.join(input_dir, 'train')\n",
    "test_image_dir = os.path.join(input_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels == k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pd.read_csv(os.path.join('train_ship_segmentations.csv'))\n",
    "print(masks.shape[0], 'mask found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "rle_0 = masks.query('ImageId==\"00021ddc3.jpg\"')['EncodedPixels']\n",
    "img_0 = masks_as_image(rle_0)\n",
    "\n",
    "ax1.imshow(img_0[:, :, 0])\n",
    "ax1.set_title('Image$_0$')\n",
    "\n",
    "rle_1 = multi_rle_encode(img_0)\n",
    "img_1 = masks_as_image(rle_1)\n",
    "\n",
    "ax2.imshow(img_1[:, :, 0])\n",
    "ax2.set_title('Image$_1$')\n",
    "print('Check Decoding->Encoding',\n",
    "      'RLE_0:', len(rle_0), '->',\n",
    "      'RLE_1:', len(rle_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into training and validation sets\n",
    "\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x > 0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "\n",
    "# some files are too small/corrupt\n",
    "unique_img_ids['file_size_in_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: os.stat(os.path.join(train_image_dir, c_img_id)).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_in_kb']>50]\n",
    "unique_img_ids['file_size_in_kb'].hist()\n",
    "\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, validation_ids = train_test_split(unique_img_ids, test_size=0.3,\n",
    "                                            stratify=unique_img_ids['ships'])\n",
    "\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "validation_df = pd.merge(masks, validation_ids)\n",
    "\n",
    "print('Training masks', train_df.shape[0])\n",
    "print('Validation masks', validation_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ships'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample the data set\n",
    "\n",
    "def sample_ships(in_df, base_rep=1500):\n",
    "    if in_df['ships'].values[0] == 0:\n",
    "        return in_df.sample(base_rep//3)\n",
    "    else:\n",
    "        return in_df.sample(base_rep, replace=(in_df.shape[0] < base_rep))\n",
    "\n",
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x + 1)//2).clip(0, 7)\n",
    "\n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "balanced_train_df['ships'].hist(bins=np.arange(10))\n",
    "balanced_train_df.ships.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size=BATCH_SIZE):\n",
    "    batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(batches)\n",
    "        for c_img_id, c_masks in batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            \n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            \n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            \n",
    "            if len(out_rgb) >= batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = make_image_gen(balanced_train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "\n",
    "ax3.imshow(mark_boundaries(batch_rgb, batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')\n",
    "\n",
    "fig.savefig('overview.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make validation set\n",
    "\n",
    "valid_x, valid_y = next(make_image_gen(validation_df, VALIDATION_SET_SIZE))\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dg_args = dict(featurewise_center = False,\n",
    "              samplewise_center = False,\n",
    "              rotation_range = 15,\n",
    "              width_shift_range = 0.1,\n",
    "              height_shift_range = 0.1,\n",
    "              shear_range = 0.01,\n",
    "              zoom_range = [0.9, 1.25],\n",
    "              horizontal_flip = True,\n",
    "              vertical_flip = True,\n",
    "              fill_mode = 'reflect',\n",
    "              data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "    \n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "    \n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, batch_size=in_x.shape[0], seed = seed, shuffle = True)\n",
    "        g_y = image_gen.flow(in_y, batch_size=in_x.shape[0], seed = seed, shuffle = True)\n",
    "        \n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "from keras import models, layers\n",
    "\n",
    "# Implementing U-Net\n",
    "\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return layers.UpSampling2D(strides)\n",
    "\n",
    "\n",
    "if UPSAMPLING_MODE == 'DECONV':\n",
    "    upsample = upsample_conv\n",
    "else:\n",
    "    upsample = upsample_simple\n",
    "    \n",
    "    \n",
    "input_img = layers.Input(t_x.shape[1:], name='RGB_Input')\n",
    "pp_in_layer = input_img\n",
    "\n",
    "\n",
    "if NET_SCALING is not None:\n",
    "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
    "\n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(pp_in_layer)\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(c1)\n",
    "p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(p1)\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c2)\n",
    "p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p2)\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c3)\n",
    "p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p3)\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
    "p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p4)\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "u6 = upsample(64, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = layers.concatenate([u6, c4])\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u6)\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "u7 = upsample(32, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = layers.concatenate([u7, c3])\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u7)\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "u8 = upsample(16, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = layers.concatenate([u8, c2])\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u8)\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "u9 = upsample(8, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = layers.concatenate([u9, c1])\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(u9)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "d = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "\n",
    "if NET_SCALING is not None:\n",
    "    d = layers.UpSamplling2D(NET_SCALING)(d)\n",
    "\n",
    "segmentation_model = models.Model(input=[input_img], outputs=[d])\n",
    "segmentation_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
